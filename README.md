# Data Audit & Validation Dashboard

A **Streamlit-based data validation and readiness auditing tool** that provides structured insights on dataset quality, structure, and suitability for analysis, dashboards, and machine learning.

This tool is diagnostic â€” it does **not modify** data, but helps you understand whatâ€™s wrong, whatâ€™s missing, and how ready your dataset is for real-world use.

---

## ğŸš€ Features

### 1. **Dataset Summary**
- Basic structure and column overview
- Missing value percentages and visual chart
- Data type and semantic classification (Numeric, Categorical, Temporal, PII)
- Non-conforming column detection

### 2. **Data Cleaning Standards**
- Lists columns with missing values
- Numeric statistics summary
- Outlier detection overview
- Additional data quality issues:
  - Constant columns
  - High-cardinality columns
  - Mixed-type columns

### 3. **Readiness Evaluation**
Readiness is evaluated in three contexts:

| Mode | Focus | Scoring Basis |
|------|--------|---------------|
| **Analysis** | General data completeness and consistency | Nulls, data types, duplicates |
| **Dashboard** | Suitability for BI dashboards | Temporal coverage, categorical diversity, PII exposure |
| **Machine Learning** | Model-level audit for ML tasks | Numeric ratio, categorical ratio, missing values |

Each mode includes a readiness score (0â€“1) and a human-readable interpretation.

---

## ğŸ§  Model-Specific Readiness

For ML Readiness, the system evaluates how well the dataset fits three major model families:

| Model | Checks Performed | Scoring Logic |
|--------|------------------|---------------|
| **Regression** | Numeric data coverage and missing ratio | 0.6 Ã— numeric ratio + 0.4 Ã— completeness |
| **Classification** | Mix of numeric & categorical features + missing ratio | 0.5 Ã— numeric + 0.3 Ã— categorical + 0.2 Ã— completeness |
| **Clustering** | Emphasis on numeric features and uniform completeness | 0.7 Ã— numeric + 0.3 Ã— completeness |

Each returns:
- **Score (0â€“1)** â€” overall readiness measure  
- **Note** â€” what the model type prefers  
- **Interpretation** â€” qualitative evaluation (Excellent / Moderate / Low)

This helps identify which types of ML workflows your data is *naturally suited* for, before any transformation or cleaning.

---

## ğŸ§© Tech Stack

- **Frontend**: Streamlit  
- **Data Processing**: Pandas, NumPy  
- **Language**: Python 3.10+  

---

## ğŸ“¦ Project Structure

```
data-audit-app/
â”‚
â”œâ”€â”€ app.py                     # Streamlit frontend logic
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ load.py                # Data loader with encoding fallback
â”‚   â””â”€â”€ validate.py            # Core validation and readiness logic
â”‚
â”œâ”€â”€ assets/                    # Example datasets (CSV/XLSX)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§® How to Run

```bash
pip install -r requirements.txt
streamlit run app.py
```

Then open `http://localhost:8501` in your browser.

---

## ğŸ’¡ Vision

A plug-and-play **data audit assistant** that helps teams:
- Diagnose dataset issues instantly
- Understand readiness for analytics or ML
- Streamline data quality assessment before heavy modeling

The app also includes a floating â€œContact for Assistanceâ€ bar for professionals seeking help with deeper cleaning or preparation.

---

## ğŸ§‘â€ğŸ’» Author

**Akshat Pande**  
Data Scientist & AI Engineer  
ğŸ“§ [mail@pandeakshat.com](mailto:mail@pandeakshat.com)  
ğŸŒ [pandeakshat.com](https://pandeakshat.com)
